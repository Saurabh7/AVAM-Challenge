{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PATH = os.getcwd()\n",
    "PATH = PATH+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this for validation with 10% from train\n",
    "is_valid = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_inplace(df):\n",
    "    df['age_level'].fillna(value=99.0, inplace=True)\n",
    "    df['city_development_index'].fillna(value=99.0, inplace=True)\n",
    "    df['gender'].fillna(value='Unknown', inplace=True)\n",
    "    df['product_category_2'].fillna(value=999999.0, inplace=True)\n",
    "    df['user_depth'].fillna(value=99.0, inplace=True)\n",
    "    df['user_group_id'].fillna(value=99.0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeFeatures(df):\n",
    "    # Make some new features with click_time column\n",
    "    df['day'] = df['DateTime'].dt.day.astype('uint8')\n",
    "    df['hour'] = df['DateTime'].dt.hour.astype('uint8')\n",
    "    df['minute'] = df['DateTime'].dt.minute.astype('uint8')\n",
    "    df['dow'] = df['DateTime'].dt.dayofweek.astype('uint8')\n",
    "    df.drop(['DateTime'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463291, 15)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(PATH+'train.csv', low_memory=False, parse_dates=['DateTime'])\n",
    "train.rename(columns={'product':'prod'}, inplace=True)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128858, 14)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(PATH+'test.csv', low_memory=False, parse_dates=['DateTime'])\n",
    "test.rename(columns={'product':'prod'}, inplace=True)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = handle_missing_inplace(train)\n",
    "train = timeFeatures(train)\n",
    "\n",
    "test = handle_missing_inplace(test)\n",
    "test = timeFeatures(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLICK_ATTR_CATS = [['prod', 'campaign_id'],['prod', 'webpage_id'], ['prod', 'product_category_1'],\n",
    "                   ['user_group_id','gender'],['user_group_id','age_level'],['user_group_id', 'user_depth'],\n",
    "                   ['prod','age_level'], ['prod','user_depth'],['product_category_1','age_level'],\n",
    "                   ['product_category_1','user_depth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Calculating confidence-weighted rate for: ['prod', 'campaign_id'].\n",
      "   Saving to: prod_campaign_id_confRate. Group Max /Mean / Median / Min: 64962 / 5939.63 / 2162.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['prod', 'webpage_id'].\n",
      "   Saving to: prod_webpage_id_confRate. Group Max /Mean / Median / Min: 81829 / 6346.45 / 1871.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['prod', 'product_category_1'].\n",
      "   Saving to: prod_product_category_1_confRate. Group Max /Mean / Median / Min: 70930 / 10774.21 / 4588.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['user_group_id', 'gender'].\n",
      "   Saving to: user_group_id_gender_confRate. Group Max /Mean / Median / Min: 140317 / 30886.07 / 13779.0 / 33\n",
      ">> Calculating confidence-weighted rate for: ['user_group_id', 'age_level'].\n",
      "   Saving to: user_group_id_age_level_confRate. Group Max /Mean / Median / Min: 140317 / 33092.21 / 16011.0 / 153\n",
      ">> Calculating confidence-weighted rate for: ['user_group_id', 'user_depth'].\n",
      "   Saving to: user_group_id_user_depth_confRate. Group Max /Mean / Median / Min: 129024 / 11582.28 / 1268.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['prod', 'age_level'].\n",
      "   Saving to: prod_age_level_confRate. Group Max /Mean / Median / Min: 58839 / 5791.14 / 1902.5 / 1\n",
      ">> Calculating confidence-weighted rate for: ['prod', 'user_depth'].\n",
      "   Saving to: prod_user_depth_confRate. Group Max /Mean / Median / Min: 142927 / 11582.28 / 1706.5 / 174\n",
      ">> Calculating confidence-weighted rate for: ['product_category_1', 'age_level'].\n",
      "   Saving to: product_category_1_age_level_confRate. Group Max /Mean / Median / Min: 54536 / 11582.28 / 5530.0 / 4\n",
      ">> Calculating confidence-weighted rate for: ['product_category_1', 'user_depth'].\n",
      "   Saving to: product_category_1_user_depth_confRate. Group Max /Mean / Median / Min: 117589 / 23164.55 / 4762.0 / 1763\n",
      "(463291, 28) (128858, 27)\n"
     ]
    }
   ],
   "source": [
    "# Find frequency of is_attributed for each unique value in column\n",
    "freqs = {}\n",
    "for cols in CLICK_ATTR_CATS:\n",
    "    \n",
    "    # New feature name\n",
    "    new_feature = '_'.join(cols)+'_confRate'    \n",
    "    \n",
    "    # Perform the groupby\n",
    "    group_object = train.groupby(cols)\n",
    "    \n",
    "    # Group sizes    \n",
    "    group_sizes = group_object.size()\n",
    "    log_group = np.log(100000) # 1000 views -> 60% confidence, 100 views -> 40% confidence \n",
    "    print(\">> Calculating confidence-weighted rate for: {}.\\n   Saving to: {}. Group Max /Mean / Median / Min: {} / {} / {} / {}\".format(\n",
    "        cols, new_feature,group_sizes.max(), np.round(group_sizes.mean(), 2), np.round(group_sizes.median(), 2),\n",
    "        group_sizes.min()))\n",
    "    \n",
    "    # Aggregation function\n",
    "    def rate_calculation(x):\n",
    "        \"\"\"Calculate the click rate. Scale by confidence\"\"\"\n",
    "        rate = x.sum() / float(x.count())\n",
    "        conf = np.min([1, np.log(x.count()) / log_group])\n",
    "        return rate * conf\n",
    "    \n",
    "    # Perform the merge\n",
    "    train = train.merge(\n",
    "        group_object['is_click']. \\\n",
    "            apply(rate_calculation). \\\n",
    "            reset_index(). \\\n",
    "            rename( \n",
    "                index=str,\n",
    "                columns={'is_click': new_feature}\n",
    "            )[cols + [new_feature]],\n",
    "        on=cols, how='left'\n",
    "    )\n",
    "    test = test.merge(\n",
    "        group_object['is_click']. \\\n",
    "            apply(rate_calculation). \\\n",
    "            reset_index(). \\\n",
    "            rename( \n",
    "                index=str,\n",
    "                columns={'is_click': new_feature}\n",
    "            )[cols + [new_feature]],\n",
    "        on=cols, how='left'\n",
    "    )\n",
    "    \n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(592149, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate target\n",
    "y = train['is_click']\n",
    "# Drop is_click and session ID from train\n",
    "train.drop(['is_click','session_id'], axis=1, inplace=True)\n",
    "\n",
    "# Create Submission dataframe\n",
    "sub = pd.DataFrame()\n",
    "sub['session_id'] = test['session_id'].astype('int')\n",
    "\n",
    "# Drop sessionID from test rows\n",
    "test.drop(['session_id'], axis=1, inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "# Create a pointer for train \n",
    "nrow_train = train.shape[0]\n",
    "\n",
    "# Concatenate for counting\n",
    "merge = pd.concat([train, test])\n",
    "print(merge.shape)\n",
    "\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(592149, 30)\n"
     ]
    }
   ],
   "source": [
    "# Identify the previous ads and history ads\n",
    "\n",
    "HISTORY_ADS = {\n",
    "    'identical_': ['user_id', 'prod', 'product_category_1', 'webpage_id', 'campaign_id'],\n",
    "    'user_prods': ['user_id', 'prod']\n",
    "}\n",
    "\n",
    "# Go through different group-by combinations\n",
    "for fname, fset in HISTORY_ADS.items():\n",
    "    \n",
    "    # Clicks in the past\n",
    "    merge['prev_'+fname] = merge.groupby(fset).cumcount().rename('prev_'+fname)\n",
    "        \n",
    "    # Clicks in the future\n",
    "    merge['future_'+fname] = merge.iloc[::-1].groupby(fset).cumcount().rename('future_'+fname).iloc[::-1]\n",
    "\n",
    "# Count cumulative subsequent clicks\n",
    "print(merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all the groupby transformations\n",
    "GROUPBY_AGGREGATIONS = [\n",
    "    # V1 - GroupBy Features #\n",
    "    #########################    \n",
    "    # Variance in day, for user_id-prod-campaign_id\n",
    "    {'groupby': ['user_id','prod','campaign_id'], 'select': 'day', 'agg': 'var'},\n",
    "    # Variance in hour, for user_id-prod-product_category_1\n",
    "    {'groupby': ['user_id','prod','product_category_1'], 'select': 'hour', 'agg': 'var'},\n",
    "    # Variance in hour, for user_id-day-campaign_id\n",
    "    {'groupby': ['user_id','day','campaign_id'], 'select': 'hour', 'agg': 'var'},\n",
    "    # Count, for user_id-day-hour'dow','hour'\n",
    "    {'groupby': ['user_id','day','hour'], 'select': 'campaign_id', 'agg': 'count'},\n",
    "    # Count, for user_id-prod\n",
    "    {'groupby': ['user_id', 'prod'], 'select': 'campaign_id', 'agg': 'count'},        \n",
    "    # Count, for user_id-prod-webpage_id\n",
    "    {'groupby': ['user_id', 'prod', 'webpage_id'], 'select': 'campaign_id', 'agg': 'count'},\n",
    "    # Count, for user_id-prod-day-hour\n",
    "    {'groupby': ['user_id','prod','day','hour'], 'select': 'campaign_id', 'agg': 'count'},\n",
    "    # Mean hour, for user_id-prod-campaign_id\n",
    "    {'groupby': ['user_id','prod','campaign_id'], 'select': 'hour', 'agg': 'mean'}, \n",
    "    \n",
    "    # V2 - GroupBy Features #\n",
    "    #########################\n",
    "    # Average clicks on app by distinct users; is it an app they return to?\n",
    "    {'groupby': ['prod'], \n",
    "     'select': 'user_id', \n",
    "     'agg': lambda x: float(len(x)) / len(x.unique()), \n",
    "     'agg_name': 'AvgprodPerDistinct'\n",
    "    },\n",
    "    # How popular is the app or channel?\n",
    "    {'groupby': ['prod'], 'select': 'campaign_id', 'agg': 'count'},\n",
    "    {'groupby': ['campaign_id'], 'select': 'prod', 'agg': 'count'},\n",
    "    \n",
    "    # V3 - GroupBy Features                                              #\n",
    "    # https://www.kaggle.com/bk0000/non-blending-lightgbm-model-lb-0-977 #\n",
    "    ###################################################################### \n",
    "    {'groupby': ['user_id'], 'select': 'campaign_id', 'agg': 'nunique'}, \n",
    "    {'groupby': ['user_id'], 'select': 'prod', 'agg': 'nunique'}, \n",
    "    {'groupby': ['user_id','day'], 'select': 'hour', 'agg': 'nunique'}, \n",
    "    {'groupby': ['user_id','prod'], 'select': 'webpage_id', 'agg': 'nunique'}, \n",
    "    {'groupby': ['user_id'], 'select': 'product_category_1', 'agg': 'nunique'}, \n",
    "    {'groupby': ['prod'], 'select': 'campaign_id', 'agg': 'nunique'}, \n",
    "    {'groupby': ['user_id', 'product_category_1', 'webpage_id'], 'select': 'prod', 'agg': 'nunique'}, \n",
    "    {'groupby': ['user_id','product_category_1','webpage_id'], 'select': 'prod', 'agg': 'cumcount'}, \n",
    "    {'groupby': ['user_id'], 'select': 'prod', 'agg': 'cumcount'}, \n",
    "    {'groupby': ['user_id'], 'select': 'webpage_id', 'agg': 'cumcount'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping by ['user_id', 'prod', 'campaign_id'], and aggregating day with var\n",
      "Grouping by ['user_id', 'prod', 'product_category_1'], and aggregating hour with var\n",
      "Grouping by ['user_id', 'day', 'campaign_id'], and aggregating hour with var\n",
      "Grouping by ['user_id', 'day', 'hour'], and aggregating campaign_id with count\n",
      "Grouping by ['user_id', 'prod'], and aggregating campaign_id with count\n",
      "Grouping by ['user_id', 'prod', 'webpage_id'], and aggregating campaign_id with count\n",
      "Grouping by ['user_id', 'prod', 'day', 'hour'], and aggregating campaign_id with count\n",
      "Grouping by ['user_id', 'prod', 'campaign_id'], and aggregating hour with mean\n",
      "Grouping by ['prod'], and aggregating user_id with AvgprodPerDistinct\n",
      "Grouping by ['prod'], and aggregating campaign_id with count\n",
      "Grouping by ['campaign_id'], and aggregating prod with count\n",
      "Grouping by ['user_id'], and aggregating campaign_id with nunique\n",
      "Grouping by ['user_id'], and aggregating prod with nunique\n",
      "Grouping by ['user_id', 'day'], and aggregating hour with nunique\n",
      "Grouping by ['user_id', 'prod'], and aggregating webpage_id with nunique\n",
      "Grouping by ['user_id'], and aggregating product_category_1 with nunique\n",
      "Grouping by ['prod'], and aggregating campaign_id with nunique\n",
      "Grouping by ['user_id', 'product_category_1', 'webpage_id'], and aggregating prod with nunique\n",
      "Grouping by ['user_id', 'product_category_1', 'webpage_id'], and aggregating prod with cumcount\n",
      "Grouping by ['user_id'], and aggregating prod with cumcount\n",
      "Grouping by ['user_id'], and aggregating webpage_id with cumcount\n",
      "(592149, 51)\n"
     ]
    }
   ],
   "source": [
    "# Apply all the groupby transformations\n",
    "for spec in GROUPBY_AGGREGATIONS:\n",
    "    \n",
    "    # Name of the aggregation we're applying\n",
    "    agg_name = spec['agg_name'] if 'agg_name' in spec else spec['agg']\n",
    "    \n",
    "    # Name of new feature\n",
    "    new_feature = '{}_{}_{}'.format('_'.join(spec['groupby']), agg_name, spec['select'])\n",
    "    \n",
    "    # Info\n",
    "    print(\"Grouping by {}, and aggregating {} with {}\".format(\n",
    "        spec['groupby'], spec['select'], agg_name\n",
    "    ))\n",
    "    \n",
    "    # Unique list of features to select\n",
    "    all_features = list(set(spec['groupby'] + [spec['select']]))\n",
    "    \n",
    "    # Perform the groupby\n",
    "    gp = merge[all_features]. \\\n",
    "        groupby(spec['groupby'])[spec['select']]. \\\n",
    "        agg(spec['agg']). \\\n",
    "        reset_index(). \\\n",
    "        rename(index=str, columns={spec['select']: new_feature})\n",
    "        \n",
    "    # Merge back to X_total\n",
    "    if 'cumcount' == spec['agg']:\n",
    "        merge[new_feature] = gp[0].values\n",
    "    else:\n",
    "        merge = merge.merge(gp, on=spec['groupby'], how='left')\n",
    "        \n",
    "     # Clear memory\n",
    "    del gp\n",
    "    gc.collect()\n",
    "\n",
    "print(merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'prod', 'campaign_id', 'webpage_id', 'product_category_1',\n",
       "       'product_category_2', 'user_group_id', 'gender', 'age_level',\n",
       "       'user_depth', 'city_development_index', 'var_1', 'day', 'hour',\n",
       "       'minute', 'dow', 'prod_campaign_id_confRate',\n",
       "       'prod_webpage_id_confRate', 'prod_product_category_1_confRate',\n",
       "       'user_group_id_gender_confRate', 'user_group_id_age_level_confRate',\n",
       "       'user_group_id_user_depth_confRate', 'prod_age_level_confRate',\n",
       "       'prod_user_depth_confRate', 'product_category_1_age_level_confRate',\n",
       "       'product_category_1_user_depth_confRate', 'prev_identical_',\n",
       "       'future_identical_', 'prev_user_prods', 'future_user_prods',\n",
       "       'user_id_prod_campaign_id_var_day',\n",
       "       'user_id_prod_product_category_1_var_hour',\n",
       "       'user_id_day_campaign_id_var_hour',\n",
       "       'user_id_day_hour_count_campaign_id', 'user_id_prod_count_campaign_id',\n",
       "       'user_id_prod_webpage_id_count_campaign_id',\n",
       "       'user_id_prod_day_hour_count_campaign_id',\n",
       "       'user_id_prod_campaign_id_mean_hour', 'prod_AvgprodPerDistinct_user_id',\n",
       "       'prod_count_campaign_id', 'campaign_id_count_prod',\n",
       "       'user_id_nunique_campaign_id', 'user_id_nunique_prod',\n",
       "       'user_id_day_nunique_hour', 'user_id_prod_nunique_webpage_id',\n",
       "       'user_id_nunique_product_category_1', 'prod_nunique_campaign_id',\n",
       "       'user_id_product_category_1_webpage_id_nunique_prod',\n",
       "       'user_id_product_category_1_webpage_id_cumcount_prod',\n",
       "       'user_id_cumcount_prod', 'user_id_cumcount_webpage_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['user_id', 'prod', 'campaign_id','webpage_id', 'product_category_1','product_category_2',\n",
    "            'user_group_id', 'gender', 'age_level', 'user_depth','city_development_index', 'var_1',\n",
    "            'day','hour','minute', 'dow']\n",
    "\n",
    "contin_vars = ['prod_campaign_id_confRate',\n",
    "       'prod_webpage_id_confRate', 'prod_product_category_1_confRate',\n",
    "       'user_group_id_gender_confRate', 'user_group_id_age_level_confRate',\n",
    "       'user_group_id_user_depth_confRate', 'prod_age_level_confRate',\n",
    "       'prod_user_depth_confRate', 'product_category_1_age_level_confRate',\n",
    "       'product_category_1_user_depth_confRate', 'prev_identical_',\n",
    "       'future_identical_', 'prev_user_prods', 'future_user_prods',\n",
    "       'user_id_prod_campaign_id_var_day',\n",
    "       'user_id_prod_product_category_1_var_hour',\n",
    "       'user_id_day_campaign_id_var_hour',\n",
    "       'user_id_day_hour_count_campaign_id', 'user_id_prod_count_campaign_id',\n",
    "       'user_id_prod_webpage_id_count_campaign_id',\n",
    "       'user_id_prod_day_hour_count_campaign_id',\n",
    "       'user_id_prod_campaign_id_mean_hour', 'prod_AvgprodPerDistinct_user_id',\n",
    "       'prod_count_campaign_id', 'campaign_id_count_prod',\n",
    "       'user_id_nunique_campaign_id', 'user_id_nunique_prod',\n",
    "       'user_id_day_nunique_hour', 'user_id_prod_nunique_webpage_id',\n",
    "       'user_id_nunique_product_category_1', 'prod_nunique_campaign_id',\n",
    "       'user_id_product_category_1_webpage_id_nunique_prod',\n",
    "       'user_id_product_category_1_webpage_id_cumcount_prod',\n",
    "       'user_id_cumcount_prod', 'user_id_cumcount_webpage_id']\n",
    "\n",
    "for v in cat_vars: \n",
    "    merge[v] = merge[v].astype('category')\n",
    "\n",
    "for v in contin_vars: \n",
    "    merge[v] = merge[v].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(592149, 51)\n"
     ]
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "for v in cat_vars:\n",
    "    merge[v] = lb.fit_transform(merge[v])\n",
    "print(merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463291, 51) (128858, 51)\n"
     ]
    }
   ],
   "source": [
    "train = merge[:nrow_train]\n",
    "test = merge[nrow_train:]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply K fold XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = y.values\n",
    "\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "\n",
    "xgb_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463291, 51) (128858, 51)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "kf = KFold(n_splits = K, random_state = 2018, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'eta': 0.005,'tree_method': \"hist\",'grow_policy': \"lossguide\",'subsample': 0.8,\n",
    "          'colsample_bytree': 0.8, 'colsample_bylevel':0.7,'objective': 'binary:logistic', \n",
    "          'eval_metric': 'auc', 'nthread':10,'random_state': 42, 'silent': True, 'max_depth':6,\n",
    "          'scale_pos_weight':13, 'gamma': 5, 'lambda': 50, 'alpha':20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:12:04] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-auc:0.623044\tvalid-auc:0.613185\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 50 rounds.\n",
      "[500]\ttrain-auc:0.657269\tvalid-auc:0.639317\n",
      "[1000]\ttrain-auc:0.671525\tvalid-auc:0.643225\n",
      "[1500]\ttrain-auc:0.682919\tvalid-auc:0.644983\n",
      "[2000]\ttrain-auc:0.693489\tvalid-auc:0.64604\n",
      "[2500]\ttrain-auc:0.702986\tvalid-auc:0.646798\n",
      "Stopping. Best iteration:\n",
      "[2887]\ttrain-auc:0.71024\tvalid-auc:0.647171\n",
      "\n",
      "[23:14:34] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-auc:0.62671\tvalid-auc:0.616717\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 50 rounds.\n",
      "[500]\ttrain-auc:0.658562\tvalid-auc:0.635702\n",
      "[1000]\ttrain-auc:0.672966\tvalid-auc:0.639259\n",
      "[1500]\ttrain-auc:0.68419\tvalid-auc:0.640691\n",
      "[2000]\ttrain-auc:0.694624\tvalid-auc:0.641602\n",
      "[2500]\ttrain-auc:0.704352\tvalid-auc:0.642311\n",
      "[3000]\ttrain-auc:0.713668\tvalid-auc:0.64278\n",
      "Stopping. Best iteration:\n",
      "[3042]\ttrain-auc:0.714423\tvalid-auc:0.642806\n",
      "\n",
      "[23:17:18] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-auc:0.625204\tvalid-auc:0.621057\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 50 rounds.\n",
      "[500]\ttrain-auc:0.656998\tvalid-auc:0.640481\n",
      "[1000]\ttrain-auc:0.670901\tvalid-auc:0.643477\n",
      "[1500]\ttrain-auc:0.682065\tvalid-auc:0.644961\n",
      "[2000]\ttrain-auc:0.692411\tvalid-auc:0.645839\n",
      "[2500]\ttrain-auc:0.702232\tvalid-auc:0.646732\n",
      "[3000]\ttrain-auc:0.711627\tvalid-auc:0.647199\n",
      "Stopping. Best iteration:\n",
      "[3438]\ttrain-auc:0.719481\tvalid-auc:0.647634\n",
      "\n",
      "[23:20:21] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-auc:0.629121\tvalid-auc:0.60795\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 50 rounds.\n",
      "[500]\ttrain-auc:0.659708\tvalid-auc:0.626504\n",
      "[1000]\ttrain-auc:0.673677\tvalid-auc:0.630689\n",
      "[1500]\ttrain-auc:0.684783\tvalid-auc:0.632658\n",
      "[2000]\ttrain-auc:0.695078\tvalid-auc:0.633781\n",
      "[2500]\ttrain-auc:0.705108\tvalid-auc:0.634412\n",
      "[3000]\ttrain-auc:0.714329\tvalid-auc:0.634842\n",
      "Stopping. Best iteration:\n",
      "[2989]\ttrain-auc:0.714127\tvalid-auc:0.634859\n",
      "\n",
      "[23:23:14] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-auc:0.622984\tvalid-auc:0.622168\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 50 rounds.\n",
      "[500]\ttrain-auc:0.656024\tvalid-auc:0.646039\n",
      "[1000]\ttrain-auc:0.670829\tvalid-auc:0.649402\n",
      "[1500]\ttrain-auc:0.682272\tvalid-auc:0.650762\n",
      "[2000]\ttrain-auc:0.692869\tvalid-auc:0.651804\n",
      "Stopping. Best iteration:\n",
      "[2406]\ttrain-auc:0.701271\tvalid-auc:0.652269\n",
      "\n",
      "Time taken is: 797.3229923248291\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for train_index, test_index in kf.split(train):\n",
    "    train_X, valid_X = train[train_index], train[test_index]\n",
    "    train_y, valid_y = target_train[train_index], target_train[test_index]\n",
    "\n",
    "    d_train = xgb.DMatrix(train_X, train_y)\n",
    "    d_valid = xgb.DMatrix(valid_X, valid_y)\n",
    "    d_test = xgb.DMatrix(test)\n",
    "    \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    model = xgb.train(params, d_train, 10000, watchlist, maximize=True, verbose_eval=500, early_stopping_rounds=50)\n",
    "                        \n",
    "    xgb_pred = model.predict(d_test)\n",
    "    xgb_preds.append(list(xgb_pred))\n",
    "\n",
    "end = time()\n",
    "print ('Time taken is:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[]\n",
    "for i in range(len(xgb_preds[0])):\n",
    "    sum=0\n",
    "    for j in range(K):\n",
    "        sum+=xgb_preds[j][i]\n",
    "    preds.append(sum / K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['is_click1']=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>is_click</th>\n",
       "      <th>is_click1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>411705</td>\n",
       "      <td>0.331929</td>\n",
       "      <td>0.639891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208263</td>\n",
       "      <td>0.110110</td>\n",
       "      <td>0.229040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239450</td>\n",
       "      <td>0.087567</td>\n",
       "      <td>0.174025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>547761</td>\n",
       "      <td>0.177963</td>\n",
       "      <td>0.364239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>574275</td>\n",
       "      <td>0.299972</td>\n",
       "      <td>0.560393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  is_click  is_click1\n",
       "0      411705  0.331929   0.639891\n",
       "1      208263  0.110110   0.229040\n",
       "2      239450  0.087567   0.174025\n",
       "3      547761  0.177963   0.364239\n",
       "4      574275  0.299972   0.560393"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply kfold LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463291, 51) (128858, 51)\n"
     ]
    }
   ],
   "source": [
    "train = merge[:nrow_train]\n",
    "test = merge[nrow_train:]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.653722\ttraining's binary_logloss: 0.238315\tvalid_1's auc: 0.636743\tvalid_1's binary_logloss: 0.240291\n",
      "[1000]\ttraining's auc: 0.669954\ttraining's binary_logloss: 0.236179\tvalid_1's auc: 0.640564\tvalid_1's binary_logloss: 0.239713\n",
      "[1500]\ttraining's auc: 0.682581\ttraining's binary_logloss: 0.234516\tvalid_1's auc: 0.641622\tvalid_1's binary_logloss: 0.239535\n",
      "Early stopping, best iteration is:\n",
      "[1898]\ttraining's auc: 0.691607\ttraining's binary_logloss: 0.233296\tvalid_1's auc: 0.642185\tvalid_1's binary_logloss: 0.239442\n",
      "Fold  1 AUC : 0.642185\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.653848\ttraining's binary_logloss: 0.237954\tvalid_1's auc: 0.639564\tvalid_1's binary_logloss: 0.241664\n",
      "[1000]\ttraining's auc: 0.671278\ttraining's binary_logloss: 0.235731\tvalid_1's auc: 0.642314\tvalid_1's binary_logloss: 0.241175\n",
      "[1500]\ttraining's auc: 0.68366\ttraining's binary_logloss: 0.234106\tvalid_1's auc: 0.643593\tvalid_1's binary_logloss: 0.240977\n",
      "[2000]\ttraining's auc: 0.694142\ttraining's binary_logloss: 0.232668\tvalid_1's auc: 0.644259\tvalid_1's binary_logloss: 0.240892\n",
      "Early stopping, best iteration is:\n",
      "[2159]\ttraining's auc: 0.697039\ttraining's binary_logloss: 0.232255\tvalid_1's auc: 0.644382\tvalid_1's binary_logloss: 0.240879\n",
      "Fold  2 AUC : 0.644382\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.654407\ttraining's binary_logloss: 0.238515\tvalid_1's auc: 0.636357\tvalid_1's binary_logloss: 0.239361\n",
      "[1000]\ttraining's auc: 0.670636\ttraining's binary_logloss: 0.236322\tvalid_1's auc: 0.639461\tvalid_1's binary_logloss: 0.238906\n",
      "[1500]\ttraining's auc: 0.683938\ttraining's binary_logloss: 0.234588\tvalid_1's auc: 0.641036\tvalid_1's binary_logloss: 0.238711\n",
      "Early stopping, best iteration is:\n",
      "[1771]\ttraining's auc: 0.690607\ttraining's binary_logloss: 0.233724\tvalid_1's auc: 0.641401\tvalid_1's binary_logloss: 0.238664\n",
      "Fold  3 AUC : 0.641401\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.655404\ttraining's binary_logloss: 0.238746\tvalid_1's auc: 0.630514\tvalid_1's binary_logloss: 0.238468\n",
      "[1000]\ttraining's auc: 0.672214\ttraining's binary_logloss: 0.236528\tvalid_1's auc: 0.634084\tvalid_1's binary_logloss: 0.238004\n",
      "[1500]\ttraining's auc: 0.684142\ttraining's binary_logloss: 0.234935\tvalid_1's auc: 0.635454\tvalid_1's binary_logloss: 0.237851\n",
      "[2000]\ttraining's auc: 0.694521\ttraining's binary_logloss: 0.233495\tvalid_1's auc: 0.636092\tvalid_1's binary_logloss: 0.237773\n",
      "Early stopping, best iteration is:\n",
      "[1978]\ttraining's auc: 0.694128\ttraining's binary_logloss: 0.23355\tvalid_1's auc: 0.636098\tvalid_1's binary_logloss: 0.237771\n",
      "Fold  4 AUC : 0.636098\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.653868\ttraining's binary_logloss: 0.238179\tvalid_1's auc: 0.64112\tvalid_1's binary_logloss: 0.240525\n",
      "[1000]\ttraining's auc: 0.670263\ttraining's binary_logloss: 0.236012\tvalid_1's auc: 0.644137\tvalid_1's binary_logloss: 0.240035\n",
      "[1500]\ttraining's auc: 0.683409\ttraining's binary_logloss: 0.234273\tvalid_1's auc: 0.645481\tvalid_1's binary_logloss: 0.239847\n",
      "Early stopping, best iteration is:\n",
      "[1749]\ttraining's auc: 0.689093\ttraining's binary_logloss: 0.233506\tvalid_1's auc: 0.6458\tvalid_1's binary_logloss: 0.239803\n",
      "Fold  5 AUC : 0.645800\n",
      "Full AUC score 0.641926\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(train.shape[0])\n",
    "sub_preds = np.zeros(test.shape[0])\n",
    "feats = [f for f in train.columns]\n",
    "\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train)):\n",
    "    trn_x, trn_y = train[feats].iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_x, val_y = train[feats].iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "    clf = LGBMClassifier(n_estimators=5000,max_depth=6,reg_alpha=.1,reg_lambda=.1,learning_rate=0.006, \n",
    "                         subsample=.9, colsample_bytree=.8 # num_leaves=20,min_split_gain=.01\n",
    "    )\n",
    "\n",
    "    clf.fit(trn_x, trn_y,\n",
    "            eval_set= [(trn_x, trn_y), (val_x, val_y)],\n",
    "            eval_metric='auc', verbose=500, early_stopping_rounds=50\n",
    "           )\n",
    "\n",
    "    oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "    sub_preds += clf.predict_proba(test[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n",
    "    del clf, trn_x, trn_y, val_x, val_y\n",
    "    gc.collect()\n",
    "\n",
    "print('Full AUC score %.6f' % roc_auc_score(y, oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['is_click2'] = sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>is_click</th>\n",
       "      <th>is_click1</th>\n",
       "      <th>is_click2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>411705</td>\n",
       "      <td>0.331929</td>\n",
       "      <td>0.639891</td>\n",
       "      <td>0.126621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208263</td>\n",
       "      <td>0.110110</td>\n",
       "      <td>0.229040</td>\n",
       "      <td>0.030823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239450</td>\n",
       "      <td>0.087567</td>\n",
       "      <td>0.174025</td>\n",
       "      <td>0.029928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>547761</td>\n",
       "      <td>0.177963</td>\n",
       "      <td>0.364239</td>\n",
       "      <td>0.053779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>574275</td>\n",
       "      <td>0.299972</td>\n",
       "      <td>0.560393</td>\n",
       "      <td>0.126358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  is_click  is_click1  is_click2\n",
       "0      411705  0.331929   0.639891   0.126621\n",
       "1      208263  0.110110   0.229040   0.030823\n",
       "2      239450  0.087567   0.174025   0.029928\n",
       "3      547761  0.177963   0.364239   0.053779\n",
       "4      574275  0.299972   0.560393   0.126358"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGB 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463291, 51) (128858, 51)\n"
     ]
    }
   ],
   "source": [
    "train = merge[:nrow_train]\n",
    "test = merge[nrow_train:]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.653367\ttraining's binary_logloss: 0.238641\tvalid_1's auc: 0.639676\tvalid_1's binary_logloss: 0.239053\n",
      "[1000]\ttraining's auc: 0.670055\ttraining's binary_logloss: 0.236456\tvalid_1's auc: 0.643633\tvalid_1's binary_logloss: 0.238458\n",
      "[1500]\ttraining's auc: 0.682794\ttraining's binary_logloss: 0.234765\tvalid_1's auc: 0.645126\tvalid_1's binary_logloss: 0.238246\n",
      "Early stopping, best iteration is:\n",
      "[1532]\ttraining's auc: 0.683585\ttraining's binary_logloss: 0.234662\tvalid_1's auc: 0.645186\tvalid_1's binary_logloss: 0.238238\n",
      "Fold  1 AUC : 0.645186\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.654971\ttraining's binary_logloss: 0.237838\tvalid_1's auc: 0.635582\tvalid_1's binary_logloss: 0.241871\n",
      "[1000]\ttraining's auc: 0.671025\ttraining's binary_logloss: 0.235679\tvalid_1's auc: 0.638497\tvalid_1's binary_logloss: 0.241434\n",
      "Early stopping, best iteration is:\n",
      "[1195]\ttraining's auc: 0.676179\ttraining's binary_logloss: 0.235008\tvalid_1's auc: 0.638855\tvalid_1's binary_logloss: 0.241383\n",
      "Fold  2 AUC : 0.638855\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.653432\ttraining's binary_logloss: 0.238643\tvalid_1's auc: 0.639766\tvalid_1's binary_logloss: 0.239115\n",
      "[1000]\ttraining's auc: 0.669285\ttraining's binary_logloss: 0.236544\tvalid_1's auc: 0.643044\tvalid_1's binary_logloss: 0.238571\n",
      "[1500]\ttraining's auc: 0.681726\ttraining's binary_logloss: 0.234931\tvalid_1's auc: 0.64444\tvalid_1's binary_logloss: 0.238377\n",
      "[2000]\ttraining's auc: 0.6932\ttraining's binary_logloss: 0.233412\tvalid_1's auc: 0.645288\tvalid_1's binary_logloss: 0.238272\n",
      "Early stopping, best iteration is:\n",
      "[2107]\ttraining's auc: 0.695496\ttraining's binary_logloss: 0.233101\tvalid_1's auc: 0.64544\tvalid_1's binary_logloss: 0.238258\n",
      "Fold  3 AUC : 0.645440\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.656658\ttraining's binary_logloss: 0.238075\tvalid_1's auc: 0.626074\tvalid_1's binary_logloss: 0.240941\n",
      "[1000]\ttraining's auc: 0.672793\ttraining's binary_logloss: 0.235864\tvalid_1's auc: 0.629766\tvalid_1's binary_logloss: 0.24051\n",
      "[1500]\ttraining's auc: 0.685414\ttraining's binary_logloss: 0.234201\tvalid_1's auc: 0.631101\tvalid_1's binary_logloss: 0.240359\n",
      "Early stopping, best iteration is:\n",
      "[1853]\ttraining's auc: 0.693272\ttraining's binary_logloss: 0.233153\tvalid_1's auc: 0.63172\tvalid_1's binary_logloss: 0.240305\n",
      "Fold  4 AUC : 0.631720\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.652052\ttraining's binary_logloss: 0.238655\tvalid_1's auc: 0.646381\tvalid_1's binary_logloss: 0.239087\n",
      "[1000]\ttraining's auc: 0.669428\ttraining's binary_logloss: 0.23645\tvalid_1's auc: 0.649684\tvalid_1's binary_logloss: 0.238441\n",
      "[1500]\ttraining's auc: 0.682713\ttraining's binary_logloss: 0.234748\tvalid_1's auc: 0.650542\tvalid_1's binary_logloss: 0.238238\n",
      "Early stopping, best iteration is:\n",
      "[1772]\ttraining's auc: 0.689042\ttraining's binary_logloss: 0.233915\tvalid_1's auc: 0.650742\tvalid_1's binary_logloss: 0.238182\n",
      "Fold  5 AUC : 0.650742\n",
      "Full AUC score 0.642277\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_preds = np.zeros(train.shape[0])\n",
    "sub_preds = np.zeros(test.shape[0])\n",
    "feats = [f for f in train.columns]\n",
    "\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train)):\n",
    "    trn_x, trn_y = train[feats].iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_x, val_y = train[feats].iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "    clf = LGBMClassifier(n_estimators=5000,max_depth=6,reg_alpha=.1,reg_lambda=.1,learning_rate=0.006, \n",
    "                         subsample=.9, colsample_bytree=.7 # num_leaves=20,min_split_gain=.01\n",
    "    )\n",
    "\n",
    "    clf.fit(trn_x, trn_y,\n",
    "            eval_set= [(trn_x, trn_y), (val_x, val_y)],\n",
    "            eval_metric='auc', verbose=500, early_stopping_rounds=50\n",
    "           )\n",
    "\n",
    "    oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "    sub_preds += clf.predict_proba(test[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n",
    "    del clf, trn_x, trn_y, val_x, val_y\n",
    "    gc.collect()\n",
    "\n",
    "print('Full AUC score %.6f' % roc_auc_score(y, oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['is_click3'] = sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>is_click</th>\n",
       "      <th>is_click1</th>\n",
       "      <th>is_click2</th>\n",
       "      <th>is_click3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>411705</td>\n",
       "      <td>0.331929</td>\n",
       "      <td>0.639891</td>\n",
       "      <td>0.126621</td>\n",
       "      <td>0.126578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208263</td>\n",
       "      <td>0.110110</td>\n",
       "      <td>0.229040</td>\n",
       "      <td>0.030823</td>\n",
       "      <td>0.031798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239450</td>\n",
       "      <td>0.087567</td>\n",
       "      <td>0.174025</td>\n",
       "      <td>0.029928</td>\n",
       "      <td>0.026155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>547761</td>\n",
       "      <td>0.177963</td>\n",
       "      <td>0.364239</td>\n",
       "      <td>0.053779</td>\n",
       "      <td>0.050414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>574275</td>\n",
       "      <td>0.299972</td>\n",
       "      <td>0.560393</td>\n",
       "      <td>0.126358</td>\n",
       "      <td>0.125206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  is_click  is_click1  is_click2  is_click3\n",
       "0      411705  0.331929   0.639891   0.126621   0.126578\n",
       "1      208263  0.110110   0.229040   0.030823   0.031798\n",
       "2      239450  0.087567   0.174025   0.029928   0.026155\n",
       "3      547761  0.177963   0.364239   0.053779   0.050414\n",
       "4      574275  0.299972   0.560393   0.126358   0.125206"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['is_click'] = (0.33*sub['is_click1']+0.33*sub['is_click2']+0.34*sub['is_click3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sub['is_click1'],sub['is_click2'],sub['is_click3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>is_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>411705</td>\n",
       "      <td>0.295986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208263</td>\n",
       "      <td>0.096566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239450</td>\n",
       "      <td>0.076197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>547761</td>\n",
       "      <td>0.155087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>574275</td>\n",
       "      <td>0.269198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  is_click\n",
       "0      411705  0.295986\n",
       "1      208263  0.096566\n",
       "2      239450  0.076197\n",
       "3      547761  0.155087\n",
       "4      574275  0.269198"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('lgb_xgb_5fold_v3.csv', float_format='%.8f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
